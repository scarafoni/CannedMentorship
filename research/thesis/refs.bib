@article{jagadeesh2005sentence,
  title={Sentence Extraction Based Single Document Summarization},
  author={Jagadeesh, J and Pingali, Prasad and Varma, Vasudeva},
  journal={International Institute of Information Technology, Hyderabad, India},
  volume={5},
  year={2005}
}
%	-features- sentence level: verb in sentence? Referring pronouns, sentence length,
%		word level:term frequency, length of word, part of speech tag, named entity
@inproceedings{lasecki2013chorus,
  title={Chorus: a crowd-powered conversational assistant},
  author={Lasecki, Walter S and Wesley, Rachel and Nichols, Jeffrey and Kulkarni, Anand and Allen, James F and Bigham, Jeffrey P},
  booktitle={Proceedings of the 26th annual ACM symposium on User interface software and technology},
  pages={151--162},
  year={2013},
  organization={ACM}
}
%	-crowd answers question
%	-vote based input
@inproceedings{kim2013toolscape,
  title={Toolscape: enhancing the learning experience of how-to videos},
  author={Kim, Juho},
  booktitle={CHI'13 Extended Abstracts on Human Factors in Computing Systems},
  pages={2707--2712},
  year={2013},
  organization={ACM}
}
%	-users annotate a video
%	-instrutions, steps introduced
%	-simple merging algorithm by pairwise distance
@inproceedings{lasecki2013warping,
  title={Warping time for more effective real-time crowdsourcing},
  author={Lasecki, Walter S and Miller, Christopher D and Bigham, Jeffrey P},
  booktitle={Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
  pages={2033--2036},
  year={2013},
  organization={ACM}
}
%	-have people transcribe video
%	-merging based on distance of words, etc...
%	-merging crowd input

@inproceedings{kulkarni2012collaboratively,
  title={Collaboratively crowdsourcing workflows with turkomatic},
  author={Kulkarni, Anand and Can, Matthew and Hartmann, Bj{\"o}rn},
  booktitle={Proceedings of the ACM 2012 conference on Computer Supported Cooperative Work},
  pages={1003--1012},
  year={2012},
  organization={ACM}
}
%	-make instructions from mturk, users specify what task they want
%	-When requesters used workflow editing tools to guide the crowdâ€™s efforts, tasks completed %successfully.
%Hu, Minqing, and Bing Liu. "Mining and summarizing customer reviews." Proceedings of the tenth ACM %SIGKDD international conference on Knowledge discovery and data mining. ACM, 2004.
%	-prediction by word closeness, frequency
%	-broadly catagorizes reviews
%	-orient search: catagories of opinion words

@inproceedings{mintz2009distant,
  title={Distant supervision for relation extraction without labeled data},
  author={Mintz, Mike and Bills, Steven and Snow, Rion and Jurafsky, Dan},
  booktitle={Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 2-Volume 2},
  pages={1003--1011},
  year={2009},
  organization={Association for Computational Linguistics}
}
%	-sentence clustering,no labeled data
%	-uses multiple sentences containing entities to find semantic similarity
%	-lexical features: words between entities, part of speech tag

@inproceedings{wallach2006topic,
  title={Topic modeling: beyond bag-of-words},
  author={Wallach, Hanna M},
  booktitle={Proceedings of the 23rd international conference on Machine learning},
  pages={977--984},
  year={2006},
  organization={ACM}
}
%	-combine bow with n-grams
%	-more effective than either
@inproceedings{sriram2010short,
  title={Short text classification in twitter to improve information filtering},
  author={Sriram, Bharath and Fuhry, Dave and Demir, Engin and Ferhatosmanoglu, Hakan and Demirbas, Murat},
  booktitle={Proceedings of the 33rd international ACM SIGIR conference on Research and development in information retrieval},
  pages={841--842},
  year={2010},
  organization={ACM}
}
%	-short text have few word occurances, bow innefective	
%	-features- metadata (author, etc)

@incollection{achananuparp2008evaluation,
  title={The evaluation of sentence similarity measures},
  author={Achananuparp, Palakorn and Hu, Xiaohua and Shen, Xiajiong},
  booktitle={Data Warehousing and Knowledge Discovery},
  pages={305--316},
  year={2008},
  publisher={Springer}
}
%	-list of ways to compare short sentences
%	-linguistic measures very good (compared with word overlap)
%	-only used bow

@inproceedings{ipeirotis2011managing,
  title={Managing crowdsourced human computation: a tutorial},
  author={Ipeirotis, Panagiotis G and Paritosh, Praveen K},
  booktitle={Proceedings of the 20th international conference companion on World wide web},
  pages={287--288},
  year={2011},
  organization={ACM}
}
%	-make work discrete, structured, iterative workflows are very good
%	-!!note- turkomatic is recursive not iterative, probably a flaw!!!
%	-humans used for labeling ml data for learning


	@inproceedings{liu2007sentence,
  title={Sentence similarity based on dynamic time warping},
  author={Liu, Xiaoying and Zhou, Yiming and Zheng, Ruoshi},
  booktitle={Semantic Computing, 2007. ICSC 2007. International Conference on},
  pages={250--256},
  year={2007},
  organization={IEEE}
}
%	-find matching parts in sentences and compute their distances
%	-very effective

@inproceedings{sheng2008get,
  title={Get another label? improving data quality and data mining using multiple, noisy labelers},
  author={Sheng, Victor S and Provost, Foster and Ipeirotis, Panagiotis G},
  booktitle={Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages={614--622},
  year={2008},
  organization={ACM}
}
%	-using mturk to label data
%	-data is hard to get a hold of
%	-good for ml purposes
@article{sorokin2008utility,
  title={Utility data annotation with amazon mechanical turk},
  author={Sorokin, Alexander and Forsyth, David},
  journal={Urbana},
  volume={51},
  number={61},
  pages={820},
  year={2008}
}
%	-same as above
@inproceedings{ml-sup-from-crowds,
  title={Collective intelligence as a source for machine learning self-supervision},
  author={Pedro, Saulo DS and Hruschka Jr, Estevam R},
  booktitle={Proceedings of the 4th International Workshop on Web Intelligence \& Communities},
  pages={5},
  year={2012},
  organization={ACM}
}
%crowd answers questions, uses answers to %anootate data

@inproceedings{ml-fused-cs,
  title={Combining human and machine intelligence in large-scale crowdsourcing},
  author={Kamar, Ece and Hacker, Severin and Horvitz, Eric},
  booktitle={Proceedings of the 11th International Conference on Autonomous Agents and Multiagent Systems-Volume 1},
  pages={467--474},
  year={2012},
  organization={International Foundation for Autonomous Agents and Multiagent Systems}
}
%use ml to fuse predictions with human input

@inproceedings{ml-cs2,
  title={On Quality Control and Machine Learning in Crowdsourcing.},
  author={Lease, Matthew},
  booktitle={Human Computation},
  year={2011}
}
%can use cs in ml for labels
%hybrid systems allow us to go beyond what humans can do

@article{howe2006rise,
  title={The rise of crowdsourcing},
  author={Howe, Jeff},
  journal={Wired magazine},
  volume={14},
  number={6},
  pages={1--4},
  year={2006}
}
%crowdsourcing can solve problems

@inproceedings{bigham2010vizwiz,
  title={VizWiz: nearly real-time answers to visual questions},
  author={Bigham, Jeffrey P and Jayant, Chandrika and Ji, Hanjie and Little, Greg and Miller, Andrew and Miller, Robert C and Miller, Robin and Tatarowicz, Aubrey and White, Brandyn and White, Samual and others},
  booktitle={Proceedings of the 23nd annual ACM symposium on User interface software and technology},
  pages={333--342},
  year={2010},
  organization={ACM}
}
%vizwiz- take pictures so blind people can help id groceries